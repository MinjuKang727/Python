{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21343,"status":"ok","timestamp":1665536803905,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"nBPGgYUnuj1t","outputId":"8f45f234-9311-4bba-b936-6ea564721a97"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"AOB9zTLajObc"},"source":["# CNN(Convolutional Neural Network)\n","- 왜 CNN을 사용하는가?\n","  - (컬러)이미지 학습 가능\n"]},{"cell_type":"markdown","metadata":{"id":"zm9LlOXlkL06"},"source":["# 축소 샘플링\n","- 합성곱을 수행한 결과 신호를 다음 계층으로 전달할 때, 모든 정보를 전달하지 않고 일부만 샘플링하여 넘겨주는 작업을 축소 샘플링(subsampling)이라고 한다.\n","- 축소 샘플링을 하는 이유는 **좀 더 가치 있는 정보만을 다음 단계로 넘겨주기 위해서이다.**\n","- 커널 수를 늘리면  특성맵의 숫자가 점차 커지게 된다. 딥러닝의 최종 목적은 정보를 결국 줄여나가야 하며 따라서 핵심 정보만 다음 계층으로 전달하는 장치가 필요하다.\n","- 컨볼루션\n","- 풀링\n","\u003cbr\u003e\u003cbr\u003e\n","\n","\u003cimg sirc=\"https://drive.google.com/uc?id=1FOwi89NjYmxfI3p8lN4ANUMDCZLUqSTb\"\u003e\n","\n","## 컨볼루션\n","- 특징을 추출하기 위한 층\n","  - 특징 : 기준 영역에서 값이 가장 큰 것\n","- 패딩(Padding)\n","  - 필터의 크기는 5x5나 7x7 등 임의의 크기로 정할 수 있다.\n","  - 필터의 크기로 인해 가장자리 부분의 데이터가 부족해서 입력과 출력의 크기가 달라지게 되는데\n","  - 이를 보정하기 위해서 입력신호의 가장자리 부분에 0을 미리 채워넣는 것을 패딩(Padding)이라고 한다.\n","  - Conv2D 계층에서는 padding 인자를 사용하여 패딩을 지정할 수 있다.\n","    - valid로 설정하면 패딩을 사용하지 말라는 뜻이다.\n","    - same은 패딩을 사용한다는 뜻이다.\n","\u003cbr\u003e\u003cbr\u003e\n","  \u003cimg src=\"https://drive.google.com/uc?id=14Hrnb2qH3izyt7lp0bCgBzo_dNtyAE4K\"\u003e\n","\n","  \u003cimg src=\"https://drive.google.com/uc?id=19hbqNYhxVoFv8rF2BU6fpk2wlfKEiuQc\"\u003e\n","\u003cbr\u003e\u003cbr\u003e\n","- 스트라이드(Stride)\n","  - 축소 샘플링에는 크게 나누어 스트라이드(stride)와 풀링(pooling)등 두가지 기법이 있다.\n","  - 스트라이드는 합성곱 필터링을 수행할 때 패치를 (예를 들면 3x3 크기)를 한 픽셀씩 옆으로 이동하면서 출력을 얻지 않고, 2픽셀씩 또는 3픽셀씩 건너 뛰면서 합성곱을 수행하는 방법이다.\n","    - 이를 스트라이드 2 또는 스트라이드 3이라고 하는데, 이렇게 하면 출력 특성맵의 크기를 1/4 또는 1/9로 줄일 수 있다.\n","\u003cbr\u003e\u003cbr\u003e\n","\n","\u003cimg src=\"https://drive.google.com/uc?id=1FTDIVe4WfclVcEiIlsxCJ2Hz_8IulLFk\"\u003e\n","\n","\n","**Conv2D(filters = 32,\n","            kernel_size = (5, 5),\n","            padding='valid',\n","            input_shape=(28, 28, 1),\n","            activation='relu',\n","            strides = (2, 2))**\n","\n","- filters : 특징의 수\n","- kernel_size : 커널의 (행, 열)\n","- padding : 경계 처리 방법을 정의\n","  - valid : 유효한 영역만 출력, 따라서 출력 이미지 사이즈는 입력 사이즈보다 작다\n","  - same : 출력 이미지 사이즈가 입력 사이즈와 동일하다.\n","- input_shape : 샘플 수를 제외한 입력 형태를 정의\n","  - 모델에서 첫 레이어일 때만 정의(행, 열, 채널 수)\n","\n","- activation : 활성화 함수 설정\n","  - relu / sigmoid / softmax / linear\n","- stride : stride 크기 지정(행, 열)/ 한번에 건너 뛸 크기를 지정\n","           \n","\u003cbr\u003e\u003cbr\u003e\n","## 풀링\n","- 특징이 아닌 것을 삭제하기 위한 층\n","- 풀링이란 CNN에서 합성곱 수행 결과를 다음 계층으로 모두 넘기지 않고, 일정 범위 내에서 (예를 들면 2x2 픽셀 범위) 가장 큰 값을 하나만 선택하여 넘기는 방법을 사용한다.\n","- 이렇게 지역 내 최대 값만 선택하는 풀링을 최대풀링(max pooling)이라고 한다.\n","  - 최대 풀링을 하면 작은 지역 공간의 대표 정보만 남기고 나머지 신호들을 제거하는 효과를 얻는다.\u003cbr\u003e\u003cbr\u003e\n","\n","\u003cimg src=\"https://drive.google.com/uc?id=12-DUHOEW7ZTySuEWq4nC2Z6JkyzQ0ye0\"\u003e\n","\n","\u003cimg src=\"https://drive.google.com/uc?id=1osqB3exUvcGwagcB5MwVcgzjhxbZLbaX\"\u003e\n","\u003cbr\u003e\u003cbr\u003e\n","\n","**MaxPooling2D(pool_size=(2, 2), stride=(2, 2))**\n","\n","- pooling_size : max pooling 크기 지정 (행, 열)\n","- stride : stride 크기 지정(행, 열)\n"]},{"cell_type":"markdown","metadata":{"id":"SE1R0IpMwaS6"},"source":["# 개와 고양이 데이터셋\n","- train : 2000장\n","- val: 1000장\n","- test : 22장\n","\u003cbr\u003e\u003cbr\u003e\n","- 각각의 데이터가 저장되어 있는 경로가 다름 --\u003e 하나의 변수에 이미지 파일 전부 다 합치기\n","- 각각의 이미지마다 크기가 다름 --\u003e 이미지 크기 동일하게 만들어주기(150, 150)\n","- 각각의 이미지에 대하여 라벨링이 필요"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665725510794,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"IdMnoxYEvXjc"},"outputs":[],"source":["# 데이터 경로 지정\n","train_dir = '/content/drive/MyDrive/Colab Notebooks/Deep_Learning/data/dogs_vs_cats_small/train'\n","test_dir = '/content/drive/MyDrive/Colab Notebooks/Deep_Learning/data/dogs_vs_cats_small/test'\n","val_dir = '/content/drive/MyDrive/Colab Notebooks/Deep_Learning/data/dogs_vs_cats_small/validation'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1665725511630,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"bCGRXN1jvXn4","outputId":"95339fb2-7766-4762-9fd2-e8477cb44d39"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n","2\n","2\n"]}],"source":["import os\n","print(len(os.listdir(train_dir)))\n","print(len(os.listdir(test_dir)))\n","print(len(os.listdir(val_dir)))"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2840,"status":"ok","timestamp":1665725515107,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"MdOyBNXnvXqA"},"outputs":[],"source":["# 하나의 변수에 이미지 파일 전부 다 합치기\n","# 픽셀값 0 ~ 255 \u003e\u003e 0 ~ 1 (분산과 연산량을 줄이자!)\n","# 이미지 크기 동일하게 만들어주기(150, 150)\n","# 라벨링\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# 픽셀값 변환\n","train_gen = ImageDataGenerator(rescale = 1./255)  # 정수값을 실수값으로 변환\n","test_gen = ImageDataGenerator(rescale = 1./255)\n","val_gen = ImageDataGenerator(rescale = 1./255)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604,"status":"ok","timestamp":1665725519015,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"q8TuWovQvXsJ","outputId":"5cea5771-822e-4230-95d8-7d1bf3db9061"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"]}],"source":["# flow_from_directory()\n","train_generator = train_gen.flow_from_directory(\n","    train_dir,  # train 이미지 경로\n","    target_size = (150, 150),  # 변환할 이미지의 크기\n","    batch_size = 100,  # 한번에 변환할 이미지 갯수\n","    class_mode = 'binary'  # 라벨링 진행\n","    # 폴더 별로 라벨링을 진행 cats폴더 안 이미지 --\u003e 0, dogs폴더 안 이미지 --\u003e 1 (알파벳 순으로 라벨링)\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665725519345,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"Hg9pg3efvXuQ","outputId":"9a42a07d-324d-4f66-dfa6-cdeeffc8e773"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 22 images belonging to 2 classes.\n"]}],"source":["test_generator = test_gen.flow_from_directory(\n","    test_dir,  # train 이미지 경로\n","    target_size = (150, 150),  # 변환할 이미지의 크기\n","    batch_size = 100,  # 한번에 변환할 이미지 갯수\n","    class_mode = 'binary'  # 라벨링 진행 : 이진분류 - binary / 다진분류 : categorical\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665725519345,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"vUBMpmDAvXwq","outputId":"a1dab022-4873-4e10-bf7d-75e0a24a67b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1000 images belonging to 2 classes.\n"]}],"source":["val_generator = val_gen.flow_from_directory(\n","    val_dir,  # train 이미지 경로\n","    target_size = (150, 150),  # 변환할 이미지의 크기\n","    batch_size = 100,  # 한번에 변환할 이미지 갯수\n","    class_mode = 'binary'  # 라벨링 진행\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665538668094,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"YhvBpJbPvXy1","outputId":"135ba16f-9f7d-44d2-cbb9-f7e91e32eec2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'cats': 0, 'dogs': 1}\n","{'cats': 0, 'dogs': 1}\n","{'cats': 0, 'dogs': 1}\n"]}],"source":["# 라벨링 결과 확인\n","print(train_generator.class_indices)\n","print(test_generator.class_indices)\n","print(val_generator.class_indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WR-CsEYT1v7t"},"outputs":[],"source":["# CNN 모델 설계\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PSfs3y92fEM"},"outputs":[],"source":["# 딥러닝 모델 생성\n","model1 = Sequential()\n","\n","# 입력층, 특징 추출부\n","model1.add(Conv2D(\n","    filters = 32,  # 특징 갯수\n","    kernel_size = (3, 3),  # 특징의 크기\n","    input_shape = (150, 150, 3),  # 입력 데이터의 모양\n","    padding = 'same',  # 입력 이미지와 출력 이미지의 크길를 동일하게\n","    activation = 'relu'  # 활성화 함수\n","))\n","\n","\n","model1.add(MaxPool2D(\n","    pool_size = (2, 2)\n","))\n","\n","model1.add(Conv2D(\n","    filters = 64,  # 특징 갯수\n","    kernel_size = (3, 3),  # 특징의 크기\n","    input_shape = (150, 150, 3),  # 입력 데이터의 모양\n","    padding = 'same',  # 입력 이미지와 출력 이미지의 크길를 동일하게\n","    activation = 'relu'  # 활성화 함수\n","))\n","\n","model1.add(MaxPool2D(\n","    pool_size = (2, 2)\n","))\n","\n","################# 특징 추출부 끝 ###################\n","model1.add(Flatten())\n","################# 분류부 시작 #####################\n","# 위에서 특징을 추출했기 때문에 층을 깊게 쌓지 않아도 됨\n","model1.add(Dense(units=256, activation = 'relu'))\n","\n","# 출력층\n","model1.add(Dense(units=1, activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U667d61s33yZ"},"outputs":[],"source":["model1.compile(\n","    loss = 'binary_crossentropy',\n","    optimizer = 'adam',\n","    metrics = ['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2863793,"status":"ok","timestamp":1665543228159,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"4WqSbJde330o","outputId":"8b0685f6-a50c-4321-8013-573eb54cb9ed"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  after removing the cwd from sys.path.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","20/20 [==============================] - 1008s 51s/step - loss: 1.9757 - accuracy: 0.5100 - val_loss: 0.6930 - val_accuracy: 0.5080\n","Epoch 2/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.6906 - accuracy: 0.5490 - val_loss: 0.6876 - val_accuracy: 0.5810\n","Epoch 3/20\n","20/20 [==============================] - 83s 4s/step - loss: 0.6902 - accuracy: 0.5995 - val_loss: 0.6957 - val_accuracy: 0.5390\n","Epoch 4/20\n","20/20 [==============================] - 81s 4s/step - loss: 0.6186 - accuracy: 0.6755 - val_loss: 0.6737 - val_accuracy: 0.5800\n","Epoch 5/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.5385 - accuracy: 0.7330 - val_loss: 0.6769 - val_accuracy: 0.6130\n","Epoch 6/20\n","20/20 [==============================] - 79s 4s/step - loss: 0.4638 - accuracy: 0.7970 - val_loss: 0.6866 - val_accuracy: 0.6070\n","Epoch 7/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.3490 - accuracy: 0.8515 - val_loss: 0.7591 - val_accuracy: 0.6300\n","Epoch 8/20\n","20/20 [==============================] - 79s 4s/step - loss: 0.2290 - accuracy: 0.9040 - val_loss: 0.9401 - val_accuracy: 0.6470\n","Epoch 9/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.1528 - accuracy: 0.9525 - val_loss: 0.9943 - val_accuracy: 0.6370\n","Epoch 10/20\n","20/20 [==============================] - 80s 4s/step - loss: 0.0865 - accuracy: 0.9790 - val_loss: 1.2388 - val_accuracy: 0.6510\n","Epoch 11/20\n","20/20 [==============================] - 80s 4s/step - loss: 0.0537 - accuracy: 0.9900 - val_loss: 1.3714 - val_accuracy: 0.6510\n","Epoch 12/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.0262 - accuracy: 0.9970 - val_loss: 1.4909 - val_accuracy: 0.6560\n","Epoch 13/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.0137 - accuracy: 0.9985 - val_loss: 1.5855 - val_accuracy: 0.6520\n","Epoch 14/20\n","20/20 [==============================] - 80s 4s/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 1.6979 - val_accuracy: 0.6660\n","Epoch 15/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7831 - val_accuracy: 0.6610\n","Epoch 16/20\n","20/20 [==============================] - 81s 4s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8515 - val_accuracy: 0.6600\n","Epoch 17/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9269 - val_accuracy: 0.6600\n","Epoch 18/20\n","20/20 [==============================] - 82s 4s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9806 - val_accuracy: 0.6630\n","Epoch 19/20\n","20/20 [==============================] - 80s 4s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9991 - val_accuracy: 0.6590\n","Epoch 20/20\n","20/20 [==============================] - 80s 4s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0540 - val_accuracy: 0.6570\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7f6c21fa1d10\u003e"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model1.fit_generator(\n","    generator = train_generator,\n","    epochs = 20,\n","    validation_data = val_generator\n",")"]},{"cell_type":"markdown","metadata":{"id":"e0HnXUK8KHp3"},"source":["#### **과대적합이 관찰 됨**\n","\n","\u003cimg src=\"https://drive.google.com/uc?id=1hkvNTSQPXQ3RmNy4a9KIwwkhL99kqjgF\"\u003e\n","\n","-\u003e 해결 방법1) 학습 데이터 증가\u003cbr\u003e\n","-\u003e 해결 방법2) 딥러닝 모델 재설계 \u003e\u003e dropout()\u003cbr\u003e\n","-\u003e 해결 방법1) 학습데이터 augmentation(데이터 증식) : 기존의 이미지에 변화를 줘서 이미지를 사용\n","  - 데이터 확장(증식) 방법\n","    - rotation_range = 360 0도에서 360도 사이에서 회전\n","      - fill_mode : 이미지 회전시, data가 없는 부분이 발생 --\u003e 이를 막아주기 위한 것\u003cbr\u003e\u003cbr\u003e\n","        \u003cimg src=\"https://drive.google.com/uc?id=19TYwvhS-T-7EnD-8b0h4T-8_Hx6TWLrM\"\u003e \n","        \n","        - 파란 부분 : 데이터가 없음\u003cbr\u003e\u003cbr\u003e\n","        - fill_mode : 'nearest' --\u003e 데이터가 없는 부분을 가장 근처 값으로 체움\u003cbr\u003e\u003cbr\u003e\n","      \u003cimg src=\"https://drive.google.com/uc?id=1WnsdHlgG9qmzxgs3sh_96Gd0IC9nNy0x\"\u003e\n","\n","    - width_shift_range = 0.1 : 전체에서 10% 내외 수평이동\n","    - height_shift_range = 0.1 : 전체에서 10% 내외 수직이동\n","    - shear_range = 0.5 : 0.5rad 내외 시계반대방향으로 변형\n","    - zoom_range = 0.3 : \n","    - Horizontal_flip = True\n","    - Vertical_flip = True\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bNoxkU3NZEe"},"outputs":[],"source":["# 과대적합 해결\n","# 학습 데이터 증가 : 2000 --\u003e 3000\n","# 딥러닝 모델 재설계 --\u003e dropout()\n","# 학습데이터 augmentation(확장) : 기존의 이미지에 변화를 줘서 이미지를 사용"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":546,"status":"ok","timestamp":1665725588783,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"h-MZG_Fn333H","outputId":"51de1ffd-e983-422c-a6c6-01cef8815776"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"]}],"source":["# 이미지 확장(증식)\n","train_aug = ImageDataGenerator(\n","    rescale = 1./255,\n","    rotation_range = 20,\n","    width_shift_range = 0.1,\n","    height_shift_range = 0.1,\n","    shear_range = 0.1,\n","    zoom_range = 0.1,\n","    horizontal_flip = True,\n","    fill_mode = 'nearest'  # 비어있는 부분을 가장 가까이에 있는 값으로 채움\n",")\n","\n","train_aug_generator = train_aug.flow_from_directory(\n","    train_dir,\n","    target_size = (150, 150),\n","    batch_size = 100,\n","    class_mode = 'binary'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbZ_OAib335h"},"outputs":[],"source":["# CNN 모델 설계\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n","\n","# 딥러닝 모델 생성\n","model2 = Sequential()\n","\n","# 입력층, 특징 추출부\n","model2.add(Conv2D(\n","    filters = 32,  # 특징 갯수\n","    kernel_size = (3, 3),  # 특징의 크기\n","    input_shape = (150, 150, 3),  # 입력 데이터의 모양\n","    padding = 'same',  # 입력 이미지와 출력 이미지의 크길를 동일하게\n","    activation = 'relu'  # 활성화 함수\n","))\n","\n","\n","model2.add(MaxPool2D(\n","    pool_size = (2, 2)\n","))\n","\n","model2.add(Conv2D(\n","    filters = 64,  # 특징 갯수\n","    kernel_size = (3, 3),  # 특징의 크기\n","    input_shape = (150, 150, 3),  # 입력 데이터의 모양\n","    padding = 'same',  # 입력 이미지와 출력 이미지의 크길를 동일하게\n","    activation = 'relu'  # 활성화 함수\n","))\n","\n","model2.add(MaxPool2D(\n","    pool_size = (2, 2)\n","))\n","\n","################# 특징 추출부 끝 ###################\n","model2.add(Flatten())\n","################# 분류부 시작 #####################\n","# 위에서 특징을 추출했기 때문에 층을 깊게 쌓지 않아도 됨\n","model2.add(Dense(units=256, activation = 'relu'))\n","model2.add(Dropout(0.4))\n","\n","# 출력층\n","model2.add(Dense(units=1, activation='sigmoid'))"]},{"cell_type":"markdown","metadata":{"id":"pqFJ_I9sQdzC"},"source":["- Dropout을 마지막 층에 한번만 넣은 이유\n","  - Dropout을 많이 하면 학습이 제대로 안될 수 있기 때문(여러번 넣어도 됨)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruuKBelE338D"},"outputs":[],"source":["model2.compile(\n","    loss = 'binary_crossentropy',\n","    optimizer = 'adam',\n","    metrics = ['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":584408,"status":"ok","timestamp":1665547552712,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"yVzDrD4933-a","outputId":"089f5f92-ce05-4616-c738-2d560f3909c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  after removing the cwd from sys.path.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","20/20 [==============================] - 89s 4s/step - loss: 0.6901 - accuracy: 0.5240 - val_loss: 0.6843 - val_accuracy: 0.5280\n","Epoch 2/20\n","20/20 [==============================] - 90s 5s/step - loss: 0.6815 - accuracy: 0.5375 - val_loss: 0.6656 - val_accuracy: 0.5720\n","Epoch 3/20\n","20/20 [==============================] - 88s 4s/step - loss: 0.6673 - accuracy: 0.5815 - val_loss: 0.6579 - val_accuracy: 0.6330\n","Epoch 4/20\n","20/20 [==============================] - 90s 4s/step - loss: 0.6492 - accuracy: 0.6365 - val_loss: 0.6464 - val_accuracy: 0.6270\n","Epoch 5/20\n","20/20 [==============================] - 94s 5s/step - loss: 0.6394 - accuracy: 0.6400 - val_loss: 0.6048 - val_accuracy: 0.6760\n","Epoch 6/20\n","20/20 [==============================] - 93s 5s/step - loss: 0.6278 - accuracy: 0.6575 - val_loss: 0.6403 - val_accuracy: 0.6540\n","Epoch 7/20\n","20/20 [==============================] - 97s 5s/step - loss: 0.6216 - accuracy: 0.6720 - val_loss: 0.6298 - val_accuracy: 0.6680\n","Epoch 8/20\n","20/20 [==============================] - 93s 5s/step - loss: 0.6122 - accuracy: 0.6665 - val_loss: 0.5931 - val_accuracy: 0.7000\n","Epoch 9/20\n","20/20 [==============================] - 88s 4s/step - loss: 0.5949 - accuracy: 0.7035 - val_loss: 0.5654 - val_accuracy: 0.7190\n","Epoch 10/20\n","20/20 [==============================] - 91s 4s/step - loss: 0.5814 - accuracy: 0.6825 - val_loss: 0.5761 - val_accuracy: 0.7010\n","Epoch 11/20\n","20/20 [==============================] - 88s 4s/step - loss: 0.5789 - accuracy: 0.6885 - val_loss: 0.5773 - val_accuracy: 0.6980\n","Epoch 12/20\n","20/20 [==============================] - 89s 4s/step - loss: 0.5701 - accuracy: 0.7195 - val_loss: 0.5677 - val_accuracy: 0.7000\n","Epoch 13/20\n","20/20 [==============================] - 90s 4s/step - loss: 0.5787 - accuracy: 0.6945 - val_loss: 0.5932 - val_accuracy: 0.6880\n","Epoch 14/20\n","20/20 [==============================] - 89s 4s/step - loss: 0.5748 - accuracy: 0.7020 - val_loss: 0.5508 - val_accuracy: 0.7120\n","Epoch 15/20\n","20/20 [==============================] - 90s 4s/step - loss: 0.5460 - accuracy: 0.7240 - val_loss: 0.5397 - val_accuracy: 0.7200\n","Epoch 16/20\n","20/20 [==============================] - 89s 4s/step - loss: 0.5348 - accuracy: 0.7345 - val_loss: 0.5401 - val_accuracy: 0.7190\n","Epoch 17/20\n","20/20 [==============================] - 88s 4s/step - loss: 0.5529 - accuracy: 0.7120 - val_loss: 0.5619 - val_accuracy: 0.7100\n","Epoch 18/20\n","20/20 [==============================] - 88s 4s/step - loss: 0.5161 - accuracy: 0.7475 - val_loss: 0.5796 - val_accuracy: 0.7120\n","Epoch 19/20\n","20/20 [==============================] - 90s 4s/step - loss: 0.5213 - accuracy: 0.7405 - val_loss: 0.5214 - val_accuracy: 0.7370\n","Epoch 20/20\n","20/20 [==============================] - 88s 4s/step - loss: 0.5124 - accuracy: 0.7465 - val_loss: 0.5442 - val_accuracy: 0.7200\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7f6c1cf24790\u003e"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["model2.fit_generator(\n","    generator = train_aug_generator,\n","    epochs = 20,\n","    validation_data = val_generator\n",")"]},{"cell_type":"markdown","metadata":{"id":"oc6-KzT0RpSB"},"source":["# 전이학습\n","- 전이학습이란 다른 데이터 셋을 사용하여 이미 학습한 모델을 유사한 다른 데이터를 인식하는데 사용하는 기법이다.\n","- 이 방법은 특히 새로 훈련시킬 데이터가 충분히 확보되지 못한 경우에 학습 효율을 높여준다.\n","- 사전학습모델을 이용하는 방법은 특성 추출(feature extraction)방식과 미세조정(fine-tuning) 방식이 있다."]},{"cell_type":"markdown","metadata":{"id":"a9f6Deq9A9Wn"},"source":["### 특성 추출 방식\n","- 컨볼루션 베이스 부분만 재사용하는 이유?\n","  - 이 부분은 상당히 일반적인 학습정보를 포함하고 있기 때문이다.\n","- 컨볼루션 계층에서도 재사용할 수 있는 정보의 수준은 몇 번째 계층인지에 따라 다르다. \n","  - 모델의 앞 단의 계층일수록 일반적인 정보를 담는다.\n","    - 예) 에지, 색상, 텍스처 등\n","  - 반면 뒷부분의 깊은 계층일 수록 추상적인 정보를 담는다.\n","    - 예) 고양이 귀, 강아지 귀 등\n","- 새롭게 분류할 클래스의 종류가 사전 학습에 사용된 데이터와 특성이 매우 다르면, \n","  - 컨볼루션 베이스 전체를 재사용해서는 안되고 **앞단의 일부 계층만을 재사용해야한다.**"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1409,"status":"ok","timestamp":1665726756318,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"boUFMqFbOqJK","outputId":"9c3bc996-57ba-4602-a643-65dee6c182c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]}],"source":["# 전이 학습\n","# 누군가가 만들어 놓은 모델 가져오기\n","from tensorflow.keras.applications import VGG16\n","\n","conv_base = VGG16(\n","    weights = 'imagenet',  # imagenet에서 사용한 가중치 가져오기\n","    include_top = False,  # 분류기를 사용할 것인가?\n","    input_shape = (150, 150, 3)\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":360,"status":"ok","timestamp":1665726840070,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"ZeZSPiKFDSvF","outputId":"37a88bb2-8011-43ba-dc81-bdec3cd5b05f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["conv_base.summary()"]},{"cell_type":"markdown","metadata":{"id":"cyoQTdMIJEif"},"source":["##### 동결 : 가중치가 갱신되는 것을 막는 것"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665728355176,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"xP0U2inYDqNO","outputId":"f64de17e-e131-4ec9-ad48-f0082d764adb"},"outputs":[{"data":{"text/plain":["26"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# 동결 : 가중치가 갱신되는 것을 막는 것\n","\n","# 학습 가능한 가중치의 갯수 확인\n","len(conv_base.trainable_weights)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665728355887,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"6y_oDuVSDqPj"},"outputs":[],"source":["# VGG16 전체 층에 대해 동결\n","conv_base.trainable = False"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":386,"status":"ok","timestamp":1665728546397,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"Gcxs_lUdDqSE","outputId":"d4713737-fc70-4e80-d774-b66c523ef63b"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# 학습 가능한 가중치의 갯수 확인\n","len(conv_base.trainable_weights)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1665728848660,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"kZNT9omLDqUX","outputId":"840ad979-a421-4030-b7ca-d9f226a9fff3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 256)               2097408   \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 16,812,353\n","Trainable params: 2,097,665\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["# 동결된 conv를 사용해서 모델 설계\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","\n","model2 = Sequential()\n","\n","model2.add(conv_base)  # 전이학습 할 모델의 특성 추출부 사용하기\n","\n","model2.add(Flatten())  # 2차원의 이미지를 1차원으로 펴줌\n","\n","model2.add(Dense(units = 256, activation='relu'))\n","\n","# 출력층\n","model2.add(Dense(units=1, activation='sigmoid'))\n","\n","model2.summary()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665728939809,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"VHCgVcimDqXB"},"outputs":[],"source":["model2.compile(loss='binary_crossentropy',\n","               optimizer='adam',\n","               metrics=['accuracy']\n","               )"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14038417,"status":"ok","timestamp":1665743076837,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"jNC7Y8k5DqZl","outputId":"536c54b8-f213-47c7-ff44-1e24bf2e0922"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  after removing the cwd from sys.path.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","20/20 [==============================] - 720s 36s/step - loss: 0.6608 - accuracy: 0.7345 - val_loss: 0.2941 - val_accuracy: 0.8670\n","Epoch 2/20\n","20/20 [==============================] - 718s 37s/step - loss: 0.2989 - accuracy: 0.8665 - val_loss: 0.2816 - val_accuracy: 0.8860\n","Epoch 3/20\n","20/20 [==============================] - 718s 37s/step - loss: 0.2681 - accuracy: 0.8875 - val_loss: 0.2739 - val_accuracy: 0.8790\n","Epoch 4/20\n","20/20 [==============================] - 715s 36s/step - loss: 0.2435 - accuracy: 0.8985 - val_loss: 0.2291 - val_accuracy: 0.9070\n","Epoch 5/20\n","20/20 [==============================] - 727s 37s/step - loss: 0.2499 - accuracy: 0.8900 - val_loss: 0.2343 - val_accuracy: 0.9060\n","Epoch 6/20\n","20/20 [==============================] - 707s 36s/step - loss: 0.2016 - accuracy: 0.9165 - val_loss: 0.2431 - val_accuracy: 0.9050\n","Epoch 7/20\n","20/20 [==============================] - 702s 36s/step - loss: 0.2174 - accuracy: 0.9070 - val_loss: 0.2497 - val_accuracy: 0.8970\n","Epoch 8/20\n","20/20 [==============================] - 718s 37s/step - loss: 0.2025 - accuracy: 0.9165 - val_loss: 0.2355 - val_accuracy: 0.9080\n","Epoch 9/20\n","20/20 [==============================] - 715s 36s/step - loss: 0.1793 - accuracy: 0.9295 - val_loss: 0.2428 - val_accuracy: 0.9040\n","Epoch 10/20\n","20/20 [==============================] - 683s 35s/step - loss: 0.1588 - accuracy: 0.9355 - val_loss: 0.2540 - val_accuracy: 0.9020\n","Epoch 11/20\n","20/20 [==============================] - 684s 35s/step - loss: 0.1646 - accuracy: 0.9330 - val_loss: 0.2391 - val_accuracy: 0.9060\n","Epoch 12/20\n","20/20 [==============================] - 676s 34s/step - loss: 0.1614 - accuracy: 0.9335 - val_loss: 0.2374 - val_accuracy: 0.9040\n","Epoch 13/20\n","20/20 [==============================] - 676s 34s/step - loss: 0.1625 - accuracy: 0.9355 - val_loss: 0.2491 - val_accuracy: 0.9000\n","Epoch 14/20\n","20/20 [==============================] - 675s 34s/step - loss: 0.1519 - accuracy: 0.9380 - val_loss: 0.2576 - val_accuracy: 0.8960\n","Epoch 15/20\n","20/20 [==============================] - 674s 34s/step - loss: 0.1658 - accuracy: 0.9305 - val_loss: 0.2660 - val_accuracy: 0.8980\n","Epoch 16/20\n","20/20 [==============================] - 678s 34s/step - loss: 0.1468 - accuracy: 0.9430 - val_loss: 0.2723 - val_accuracy: 0.8970\n","Epoch 17/20\n","20/20 [==============================] - 674s 34s/step - loss: 0.1419 - accuracy: 0.9435 - val_loss: 0.2587 - val_accuracy: 0.8920\n","Epoch 18/20\n","20/20 [==============================] - 674s 34s/step - loss: 0.1283 - accuracy: 0.9540 - val_loss: 0.2600 - val_accuracy: 0.8990\n","Epoch 19/20\n","20/20 [==============================] - 674s 34s/step - loss: 0.1383 - accuracy: 0.9445 - val_loss: 0.2833 - val_accuracy: 0.8920\n","Epoch 20/20\n","20/20 [==============================] - 675s 34s/step - loss: 0.1332 - accuracy: 0.9470 - val_loss: 0.2724 - val_accuracy: 0.8950\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7f1e87d8a890\u003e"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model2.fit_generator(\n","    generator = train_aug_generator,\n","    epochs = 20,\n","    validation_data = val_generator\n",")"]},{"cell_type":"markdown","metadata":{"id":"472JnJGyYcT9"},"source":["- 지금 사용한 모델의 특성 추출부 : 다른 사람이 사용한 가중치를 사용하고 있음\n","\u003cbr\u003e --\u003e 우리가 가지고 있는 데이터에 완벽하게 맞는 모델은 아님\n","\n","## 미세조정방식\n","- 모델 베이스 중 상위 몇개의 계층은 전 결합층 분류기와 함께 새로 학습시키는 방식이다.\n","- 최종 분류기의 계수가 랜덤하게 초기화 되어 있으므로 이를 먼저 학습시키며 이때 사전학습 모델의 컨볼루션 베이스를 초기에는 고정해야 한다.\n","- 먼저 분류기를 계수를 학습시킨 다음에(즉, 이 동안은 미세조정을 하지 않도록 상위 계층의 계수를 고정시켜 두고), 그 이후에 미세조정을 해야 한다.\n","- 처음부터 베이스 상위 계층의 계수를 같이 훈련시키면 분류기에서 발생하는 큰 에러 값으로 인해, 사전 학습된 정보가 많이 손실된다.\n","\n","1) 사전 학습된 기본 네트워크(전이 학습 모델(예: VGG16)-Conv_base) 상단에 새로운 네트워크(분류부(Dense))를 추가한다.\u003cbr\u003e\n","2) 기본 네트워크를 고정(=동결)시킨다.  \u003e\u003e trainable = False\u003cbr\u003e\n","3) 새로 추가한 부분을 학습 시킨다.\u003cbr\u003e\n","4) 기본 계층(컨볼루션 베이스 부분) 중에 학습시킬 상위 부분의 고정을 푼다.\u003cbr\u003e\n","5) 고정을 푼 계층과 새로 추가한 계층을 함께 훈련시킨다.\u003cbr\u003e\n","- 미세 조정을 천천히 수행하기 위해서 느린 학습 속도를 선택한다.\n","갑자기 큰 변화를 주면 사전 학습된 내용이 훼손되기 때문이다.\n","\n","\u003cimg src=\"https://drive.google.com/uc?id=1adMzEpdZHC5iQjMqf4tNYQ4g1QwBHI-m\"\u003e"]},{"cell_type":"markdown","metadata":{"id":"B2lahtzjc40y"},"source":[]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1665743180461,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"i5q4TOVxc1A6","outputId":"f19ca687-b7d5-48a7-f452-3808463d7bd9"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# model2에서 학습 가능한 가중치의 갯수 확인\n","len(model2.trainable_weights)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1665743181533,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"QRCRG-HbcMm8","outputId":"5d366149-43a3-4680-b52c-1919e7f1f56b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["conv_base.summary()"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":975,"status":"ok","timestamp":1665743183479,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"zsMhtO-hfIVd"},"outputs":[],"source":["from tensorflow.keras.applications import VGG16\n","\n","conv_base = VGG16(\n","    weights = 'imagenet',  # imagenet에서 사용한 가중치 가져오기\n","    include_top = False,  # 분류기를 사용할 것인가?\n","    input_shape = (150, 150, 3)\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665743184025,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"RlV7yR-5cMpk"},"outputs":[],"source":["# block_conv1 ~ 3 층을 학습시켜보자\n","# for layer in conv_base.layers :\n","#   print(layer.name)\n","\n","# block_conv1층부터 하위의 층의 동결을 해제\n","set_trainable = False\n","for layer in conv_base.layers :\n","  if layer.name == 'block_conv1' :\n","    set_trainable = True\n","\n","  if set_trainable == True :\n","    layer.trainable = True\n","  else :\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665743186637,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"OT2NDH_5d8aE","outputId":"98a01087-5e13-4dca-b42a-14a2d137c287"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n","                                                                 \n"," flatten_1 (Flatten)         (None, 8192)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 256)               2097408   \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 16,812,353\n","Trainable params: 2,097,665\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["# 동결된 conv를 사용해서 모델 설계\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","\n","model2 = Sequential()\n","\n","model2.add(conv_base)  # 전이학습 할 모델의 특성 추출부 사용하기\n","\n","model2.add(Flatten())  # 2차원의 이미지를 1차원으로 펴줌\n","\n","model2.add(Dense(units = 256, activation='relu'))\n","\n","# 출력층\n","model2.add(Dense(units=1, activation='sigmoid'))\n","\n","model2.summary()"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665743188094,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"R41ar01KcMsA","outputId":"eaa71d25-dcca-4180-cbe0-70c09ee2a51b"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["len(model2.trainable_weights)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665743220825,"user":{"displayName":"Minju Kang","userId":"01677946280694970314"},"user_tz":-540},"id":"O_AjWkusCGC8"},"outputs":[],"source":["model2.compile(loss='binary_crossentropy',\n","               optimizer='adam',\n","               metrics=['accuracy']\n","               )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Nr7byD4dCGC9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  after removing the cwd from sys.path.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","20/20 [==============================] - 679s 34s/step - loss: 1.0349 - accuracy: 0.5895 - val_loss: 0.5055 - val_accuracy: 0.7430\n","Epoch 2/20\n","20/20 [==============================] - 677s 34s/step - loss: 0.4259 - accuracy: 0.8285 - val_loss: 0.3469 - val_accuracy: 0.8570\n","Epoch 3/20\n","20/20 [==============================] - 674s 34s/step - loss: 0.3512 - accuracy: 0.8560 - val_loss: 0.2895 - val_accuracy: 0.8890\n","Epoch 4/20\n","20/20 [==============================] - 677s 34s/step - loss: 0.3091 - accuracy: 0.8670 - val_loss: 0.2657 - val_accuracy: 0.9010\n","Epoch 5/20\n","20/20 [==============================] - 673s 34s/step - loss: 0.2746 - accuracy: 0.8860 - val_loss: 0.2534 - val_accuracy: 0.8980\n","Epoch 6/20\n"," 9/20 [============\u003e.................] - ETA: 4:08 - loss: 0.2821 - accuracy: 0.8811"]}],"source":["model2.fit_generator(\n","    generator = train_aug_generator,\n","    epochs = 20,\n","    validation_data = val_generator\n",")"]},{"cell_type":"markdown","metadata":{"id":"HLLeXIocnSBq"},"source":["### 하위층부터 동결하는 이유?\n","- 출력층에서 나타난 오차를 역전파에서 학습을 시키려고 하는데 조금씩 학습을 시키기 위해 하위층부터 동결함\n","\n","\u003cimg src=\"https://drive.google.com/uc?id=194-LrTLAtp1FXmz7hoWMMad_tFVFU9f-\"\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yc266n_Jd8dB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yz5ajpNZd8fx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ut5q4wQCd8iM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOhcF11fd8lG"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPukGdZTviQH3mFEZ8CspV4","collapsed_sections":[],"mount_file_id":"1TPiT1d2AKj3xzOZMp95iFCARUhs0ZNSv","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}