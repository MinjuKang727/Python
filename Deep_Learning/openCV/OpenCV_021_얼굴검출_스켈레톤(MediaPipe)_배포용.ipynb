{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48de9623",
   "metadata": {},
   "source": [
    "<img src=\"./lecture_image/00_title.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6130b7d",
   "metadata": {},
   "source": [
    "<table border=1 width=100%>\n",
    "    <tr><td style=\"border: 1px solid black; width:600px; height:30px; text-align: center;\"><font size=4 color=blue><b>[21차시] 학습목표</b></font></td></tr>       \n",
    "    <tr><td style=\"border: 1px solid black; text-align: left;\"><font size=3>\n",
    "        \n",
    "○ Mediapipe 라이브러리를 활용할 수 있다 <br><br>\n",
    "○ Mediapipe 라이브러리를 이용하여 얼굴 특성을 추출할 수 있다 <br><br>\n",
    "○ Mediapipe 라이브러리를 이용하여 동작 특성을 추출할 수 있다 </font></td></tr>   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301e97a",
   "metadata": {},
   "source": [
    "# Mediapipe 라이브러리를 이용한 얼굴 3D 데이터 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72c546",
   "metadata": {},
   "source": [
    "- 라이브 및 스트리밍 미디어를 위한 플랫폼 간 사용자 지정 가능한 ML 솔루션을 제공\n",
    "- mediapipe 라이브러리 : https://google.github.io/mediapipe/getting_started/python\n",
    "- 기능\n",
    "<table width=800>\n",
    "    <tr>\n",
    "        <td><center><b>얼굴 검출</b></center></td>\n",
    "        <td><center><b>얼굴 Mesh</b></center></td>\n",
    "        <td><center><b>홍채 검출</b></center></td>\n",
    "        <td><center><b>손동작 검출</b></center></td>\n",
    "        <td><center><b>동작 검출</b></center></td>\n",
    "        <td><center><b>전체동작</b></center></td>\n",
    "    </tr>     \n",
    "    <tr>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_face_detection.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_face_mesh.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_iris_tracking.gif \"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_hand_tracking.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_pose_tracking.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_holistic_tracking.gif\"></td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td><center><b>헤어 분리</b></center></td>\n",
    "        <td><center><b>객체 검출</b></center></td>\n",
    "        <td><center><b>박스 추적</b></center></td>\n",
    "        <td><center><b>모션 추적</b></center></td>\n",
    "        <td><center><b>3D객체 검출</b></center></td>\n",
    "        <td><center><b>템플릿 매칭</b></center></td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_hair_segmentation.gif\"></td>        \n",
    "        <td><img src=\"./lecture_image/21_mediapipe_object_detection.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_box_tracking.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_instant_motion_tracking.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_objectron_chair.gif\"></td>\n",
    "        <td><img src=\"./lecture_image/21_mediapipe_template_matching.gif\"></td>\n",
    "    </tr> \n",
    "</table>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86e202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 프롬프트 창에서 설치\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca08ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# No module named 'mediapipe'가 뜨는 경우\n",
    "#   - 설치 폴더 (아래 설치내용 확인) 확인해서 .\\anaconda3\\envs\\opencv\\lib\\site-packages로 이동\n",
    "\n",
    "# No module named 'mediapipe.python._framework_bindings가 뜨는 경우\n",
    "#   - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a70b8",
   "metadata": {},
   "source": [
    "## 얼굴 메시 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513aefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 얼굴 메시를 추출하는 라이브러리 가져오기\n",
    "# 결과를 시각화하는 라이브러리\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 얼굴 메시를 추출하는 라이브러리 가져오기\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# 얼굴, 홍채 등 찾는 객체에 맞는 라이브러리를 가져오면 됨\n",
    "\n",
    "#시각화 설정(선 두께, 원의 반지름)\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# 영상 불러오기\n",
    "cap=cv2.VideoCapture(\"./image/face3.mp4\")\n",
    "\n",
    "# 얼굴 메시 추출(최소 검출 정확도, 최소 추적 정확도)\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5,\n",
    "                          min_tracking_confidence=0.5) as face_mesh :\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret :\n",
    "            break\n",
    "            \n",
    "        # 이미지 쓰기 불가 설정 (속도때문에...)\n",
    "        frame.flags.writeable = False\n",
    "        \n",
    "        # 메시 검출\n",
    "        results = face_mesh.process(frame)\n",
    "        \n",
    "        frame.flags.writeable = True\n",
    "        \n",
    "        # 랜드마크를 서로 연결 (매시)\n",
    "        # 랜드마크 점이 검출되었다면\n",
    "        if results.multi_face_landmarks :\n",
    "            print(results.multi_face_landmarks)\n",
    "            # 검출 랜드마크를 하나씩 가져온다.\n",
    "            for face_landmark in results.multi_face_landmarks :\n",
    "                # 랜드마크들끼리 선으로 연결\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=frame,\n",
    "                landmark_list=face_landmark,\n",
    "                # 얼굴 전체\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                # 그리기 설정\n",
    "                landmark_drawing_spec=drawing_spec,\n",
    "                connection_drawing_spec=drawing_spec\n",
    "            )\n",
    "        cv2.imshow(\"face mesh\", frame)\n",
    "        \n",
    "        key = cv2.waitKey(33)\n",
    "        \n",
    "        if key == 49 :\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29591c1f",
   "metadata": {},
   "source": [
    "### 얼굴 매시 + 손 스켈레톤 검출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6aa6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 얼굴 메시를 추출하는 라이브러리 가져오기\n",
    "# 결과를 시각화하는 라이브러리\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 얼굴 메시를 추출하는 라이브러리 가져오기\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "# 손 스켈레톤 추출 라이브러리 가져오기\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "# 얼굴, 홍채 등 찾는 객체에 맞는 라이브러리를 가져오면 됨\n",
    "\n",
    "#시각화 설정(선 두께, 원의 반지름)\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# 영상 불러오기\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# 얼굴 메시 추출(최소 검출 정확도, 최소 추적 정확도)\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5,\n",
    "                          min_tracking_confidence=0.5) as face_mesh :\n",
    "    with mp_hands.Hands(model_complexity=0,\n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5) as hands :\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret :\n",
    "                break\n",
    "\n",
    "            # 이미지 쓰기 불가 설정 (속도때문에...)\n",
    "            frame.flags.writeable = False\n",
    "\n",
    "            # 메시 검출\n",
    "            results = face_mesh.process(frame)\n",
    "            frame.flags.writeable = True\n",
    "\n",
    "            # 랜드마크를 서로 연결 (매시)\n",
    "            # 랜드마크 점이 검출되었다면\n",
    "            if results.multi_face_landmarks :\n",
    "                # 검출 랜드마크를 하나씩 가져온다.\n",
    "                for face_landmark in results.multi_face_landmarks :\n",
    "                    # 랜드마크들끼리 선으로 연결\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=frame,\n",
    "                    landmark_list=face_landmark,\n",
    "                    # 얼굴 전체\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    # 그리기 설정\n",
    "                    landmark_drawing_spec=drawing_spec,\n",
    "                    connection_drawing_spec=drawing_spec\n",
    "                )\n",
    "                    \n",
    "            frame.flags.writeable = False\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(frame)\n",
    "\n",
    "            # Draw the hand annotations on the image.\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                    image=frame,\n",
    "                    landmark_list=hand_landmarks,\n",
    "                    connections=mp_hands.HAND_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            cv2.imshow(\"face mesh + hand skeleton\", cv2.flip(frame, 1))\n",
    "\n",
    "            key = cv2.waitKey(33)\n",
    "\n",
    "            if key == 49 :\n",
    "                break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9efaa",
   "metadata": {},
   "source": [
    "## 얼굴, 왼손, 오른손, 동작 검출 (스켈레톤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17cf7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 그리기 기능\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 스켈레톤 추출 기능(전체) - 양손, 양손가락, 얼굴, 몸통, 다리, 발\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "cap = cv2.VideoCapture(\"./image/face4.mp4\")\n",
    "\n",
    "# 랜드마크 점 찍기\n",
    "drawing_spec1 = mp_drawing.DrawingSpec(thickness=1, color=(0, 0, 255))\n",
    "# 선 그리기\n",
    "drawing_spec2 = mp_drawing.DrawingSpec(thickness=3, color=(255, 0, 0))\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic :\n",
    "    while cap.isOpened() :\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret :\n",
    "            break\n",
    "            \n",
    "        frame.flags.writeable = False\n",
    "        results = holistic.process(frame)\n",
    "        frame.flags.writeable = True\n",
    "        \n",
    "        # 몸통/ 다리/ 발 부분의 스켈레톤 그리기\n",
    "        mp_drawing.draw_landmarks(frame, \n",
    "                                  results.pose_landmarks,\n",
    "                                 mp_holistic.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=drawing_spec1,\n",
    "                                  connection_drawing_spec=drawing_spec2\n",
    "                                 )\n",
    "        cv2.imshow(\"skeleton\", frame)\n",
    "        \n",
    "        key = cv2.waitKey(33)\n",
    "        \n",
    "        if key == 49 :\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380b799",
   "metadata": {},
   "source": [
    "### 손 스켈레톤 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23e4a1e",
   "metadata": {},
   "source": [
    "# 응용 : 자세 분석\n",
    "- https://github.com/spmallick/learnopencv/tree/master/Posture-analysis-system-using-MediaPipe-Pose\n",
    "\n",
    "- WorkFlow\n",
    "  - 각도를 확인할 관심 지점(랜드마크) 검색\n",
    "  - 표준 샘플 이미지(옆면 이미지)에 대한 분석 수행\n",
    "  - 좋은 자세와 나쁜 자세에 대한 임계값 범위를 검색\n",
    "  - 영상에 적용하기\n",
    "  \n",
    "<img src=\"./lecture_image/21_MediaPipe-pose-application.png\" width=70%>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce10223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524759d",
   "metadata": {},
   "source": [
    "- 오프셋 거리 계산\n",
    "  - 측면보기 상태에서 두 포인트 (눈, 어깨, 골반) 사이의 거리를 계산\n",
    "  \n",
    "\\begin{align}\n",
    "distance =  \\sqrt{(x2 - x1)^2+(y2 - y1)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0004b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6514c61",
   "metadata": {},
   "source": [
    "- 관심 선에서 y축으로 종속된 각도 계산\n",
    "\n",
    "<img src=\"./lecture_image/21_calculate_arc.jpg\" width=40%>\n",
    "\n",
    "\\begin{align}\n",
    "\\theta = \\arccos (\\frac{\\vec{P_{12}}.\\vec{P_{13}}}{|\\vec{P_{12}}|.|\\vec{P_{13}}|})\n",
    "= \\arccos (\\frac{y_1^2 - y_1.y_2}{y_1\\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374220f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85307ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18b757",
   "metadata": {},
   "source": [
    "# 응용 : Human Action Recognition using Detectron2 and LSTM\n",
    "  - https://learnopencv.com/human-action-recognition-using-detectron2-and-lstm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e4535",
   "metadata": {},
   "source": [
    "<table border=1 width=100%>\n",
    "    <tr><td style=\"border: 1px solid black; width:600px; height:40px; text-align: center;\"><font size=4 color=blue><b>[21차시] 정리하기</b></font></td></tr>       \n",
    "    <tr><td style=\"border: 1px solid black; text-align: left;\"><font size=3>○            \n",
    "        </font></td></tr>   \n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
